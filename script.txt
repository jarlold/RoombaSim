You ever try and do something that seems pretty simple in the moment, but the
more and more you look into it, the more and more complicated it gets? Until
what you thought would have been a quick 1 week thing has turned into a
multi-year long rabbit hole?


Well, I found a broken roomba a while ago, and thought I'd clean it up and get
it running again. The motors and batteries were still working fine, but the
little ARM chip that runs the guy was totally corroded. I figured I'd hook it up
to a single-board computer and write some code to run the guy on there.

In my head, this was a simple 1 week project, so I naturally doubled that time-
thinking it'd be a 2 week project. That was about 15 months ago.

See I didn't have the IR lighthouses that help the roomba avoid getting stuck,
and I didn't have the EE know-how to replace them. So I decided it'd be wise to
write a "quick" simulation of the roomba, and test out various roomba-logics.

MISTAKE

Things like "when you bump into a wall, turn a random number of degrees" or
"when you bump into a wall turn 90 degrees". That sort of thing. To do this, I
wrote a little 2d physics simulator, added some random noise to the roombas
movement, and then started testing various forms of logic out.

I quickly realized that you can actually make a lot of different complex roomba
logics, if you keep basic metrics on the roombas. For example, by keeping tabs
of how many times the roomba bumped into a wall, and how long its been since the
last wall bump, we can intelligently make the roomba increase it's bearing. 

After fiddling with a few idea on my own, I realized that there was a lot of
room for optimizations that I wouldn't be able to predict myself. So I wrote in
a lot of these different metrics for the roomba, based off what the roomba would
be able to actually record in real life. Then, I thought, I'd write a tiny,
simple, genetic algorithm to optimize roomba behaviour.

MISTAKE

But an easy one to make, see to me, the term "genetic algorithm" meant:
"changing random things until it works"- which is not an inaccurate
description, it's just a very reductive one. 

So I thought I'd write in a "quick and simple :tm:" densely connected neural
network to map these roomba-metrics to the roomba's new bearings.

If you don't know what a densely connected neural network is, that's out of
scope of this video, but just know it's a simple way of mapping arbitrary inputs
into arbitrary outputs. Wikipedia calls it a "general regressor"

So a DNN of infinite size could in theory map f(I1, I2, I3...) -> (O1, O2,
O3...) for any Is or Os. Again, a densely connected (or fully connected) neural
network is like, the easiest of all neural networks. Especially since I only
have to do the forward pass. So it shouldn't take me much time to do.

MISTA- psych. I actually wrote it drunk in one afternoon. Again, it sounds hard
and can do a lot of cool stuff, but it is just basic linear algebra.

The real mistake really was adding in a genetic algorithm, see I greatly
underestimated how complicated of a thing genetic algorithms can be.

Initially, I thought I would just run a roomba simulation a few times, change
some of the weights randomly, and the re-run the simulation. If the roomba did
better, I'd keep the changes, if it did worse I'd revert back to the previous
ones. Then I'd just make that shit into a for loop and let it run while I go do
important things.

<<minecraft logo here>>

Turns out, people who did their PhDs on this topic weren't all scam artists
pretending to be way smarter than they are. It's actually just a really
complicated (and strange) thing. 


